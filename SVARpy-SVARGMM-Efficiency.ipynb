{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFJ4tJskU4Qp"
   },
   "source": [
    "## SVARpy: SVAR-GMM Efficiency Gains\n",
    " \n",
    "This file allows to quickly recreate the SVAR and the three estimators used in the Monte Carlo simulation in Keweloh, Sascha Alexander, and Wang, Shu. \"Higher Moments and  Efficiency Gains in Recursive Structural Vector Autoregressions.\" Oxford Bulletin of Economics and Statistics (2025).\n",
    "\n",
    "\n",
    "For a full replication file see [Github](https://github.com/Saschakew/Replication-Higher-Moments-and--Efficiency-Gains-in-Recursive-Structural-Vector-Autoregressions).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOA74cJ859Q-"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "\n",
    "# If required pip install SVARpy package\n",
    "if True:\n",
    "    !pip install pathos \n",
    "    !pip install SVARp \n",
    "\n",
    "import numpy as np \n",
    "import SVAR as SVAR\n",
    "import SVAR.MoG as MoG\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRw2knRt6PD9"
   },
   "source": [
    "We simulate a recursive SVAR(0) $u_t=B_0 \\epsilon_t$ with five variables \n",
    "\\begin{align} \n",
    "\\begin{bmatrix}\n",
    "u_{1t} \\\\\n",
    "u_{2t} \\\\\n",
    "u_{3t} \\\\\n",
    "u_{4t} \\\\\n",
    "u_{5t} \\\\\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "10 & 0  & 0 & 0 & 0\\\\\n",
    "5 & 10 & 0 & 0 & 0\\\\\n",
    "5 & 5 & 10 & 0 & 0\\\\\n",
    "5 & 5 & 5 & 10 & 0\\\\\n",
    "5 & 5 & 5 & 5 & 10\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\epsilon_{1t} \\\\\n",
    "\\epsilon_{2t} \\\\\n",
    "\\epsilon_{3t} \\\\\n",
    "\\epsilon_{4t} \\\\\n",
    "\\epsilon_{5t} \\\\\n",
    "\\end{bmatrix}   \n",
    "\\end{align}  \n",
    " and i.i.d. structural shocks with skewness $0.9$ and excess kurtosis $2.4$ from a two-component mixture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcSV_poGv8kl"
   },
   "outputs": [],
   "source": [
    "n = 5  # Number of variables\n",
    "T = 500  # Number of observations\n",
    "# Specitfy B0\n",
    "B0 = np.eye(n)\n",
    "\n",
    "# shocks\n",
    "mu1, sigma1 = (-0.2, np.power(0.7, 2))\n",
    "mu2, sigma2 = (0.7501187648456057, np.power(1.4832737225521377, 2))\n",
    "lamb = 0.7895\n",
    "Omega = np.array([[mu1, sigma1], [mu2, sigma2]])\n",
    "\n",
    "# Specitfy B_true\n",
    "B_true = np.array([[1, 0  , 0  , 0, 0],\n",
    "                    [0.5, 1, 0 , 0, 0],\n",
    "                    [0.5, 0.5, 1, 0, 0],\n",
    "                    [0.5, 0.5,  0.5  , 1, 0],\n",
    "                    [0.5, 0.5,  0.5  , 0.5 , 1 ]])\n",
    "\n",
    "V = np.linalg.cholesky(np.matmul(B_true, np.transpose(B_true)))\n",
    "O = np.matmul(np.linalg.inv(V), B_true)\n",
    "b_true = SVAR.SVARutil.get_Skewsym(O)\n",
    "B_true = B_true * 10\n",
    "\n",
    "# Draw structural shocks\n",
    "eps = np.empty([T, n])\n",
    "omega = np.zeros([n, 6])\n",
    "for i in range(n):\n",
    "        eps[:, i] = MoG.MoG_rnd(Omega, lamb, T)\n",
    "        momentstmp = SVAR.MoG.MoG_Moments(Omega, lamb)[1:]\n",
    "        for i in range(n):\n",
    "            omega[i, :] = momentstmp\n",
    "\n",
    "# Generate reduced form shocks\n",
    "u = np.matmul(B_true, np.transpose(eps))\n",
    "u = np.transpose(u)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator: Cholesky\n",
    "\n",
    "\n",
    "The simulation compares three estimators, each imposing a recursive SVAR.\n",
    "The first estimator $\\hat{B}_{\\textbf{2}}$ is the just-identified recursive SVAR  estimator based on Equation (3) obtained by applying the Cholesky decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = 'GMM'\n",
    "estimator_name = 'Cholesky'\n",
    "prepOptions = dict()\n",
    "prepOptions['printOutput'] = True\n",
    "prepOptions['bstartopt'] = 'Rec'\n",
    "prepOptions['n_rec'] = n\n",
    "prepOptions['addThirdMoments'] = False\n",
    "prepOptions['addFourthMoments'] = False\n",
    "prepOptions['moments_MeanIndep'] = False\n",
    "prepOptions['moments_blocks'] = False\n",
    "prepOptions['onlybivariate'] = False\n",
    "prepOptions['Wpara'] = 'Uncorrelated'\n",
    "prepOptions['Avarparametric'] = 'Uncorrelated'\n",
    "prepOptions['Wstartopt'] = 'I'\n",
    "prepOptions['S_func'] = False\n",
    "prepOptions['kstep'] = 1 \n",
    "\n",
    "\n",
    "GMM_out = SVAR.SVARest(u, estimator=estimator, prepOptions=prepOptions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator: SVAR-CUE all moments\n",
    "\n",
    "The second estimator $\\hat{B}_{\\textbf{2} + \\textbf{SK}}$ is the overidentified recursive SVAR estimator based on Equation (10).\n",
    "\n",
    "Overidentified GMM estimators with many moment conditions can suffer from a small sample bias. Therefore, the overidentified estimators are implemented using a continuous updating estimator (CUE) instead of a GMM estimator. The CUE continuously updates the weighting, that is, the weighting matrix using the assumption of independent shocks to estimate the efficient weighting matrix, see Keweloh (2023). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = 'CUE'\n",
    "estimator_name = 'CUE-MI'\n",
    "prepOptions = dict()\n",
    "prepOptions['printOutput'] = True\n",
    "prepOptions['bstartopt'] = 'Rec'\n",
    "prepOptions['n_rec'] = n\n",
    "prepOptions['addThirdMoments'] = True\n",
    "prepOptions['addFourthMoments'] = True\n",
    "prepOptions['moments_MeanIndep'] = False\n",
    "prepOptions['moments_blocks'] = False\n",
    "prepOptions['onlybivariate'] = False\n",
    "prepOptions['Wpara'] = 'Independent'\n",
    "prepOptions['Avarparametric'] = 'Independent'\n",
    "prepOptions['S_func'] = True\n",
    "prepOptions['WupdateInOutput'] = False\n",
    "\n",
    "\n",
    "\n",
    "GMM_out = SVAR.SVARest(u, estimator=estimator, prepOptions=prepOptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator: SVAR-GMM only non-redundant moments\n",
    "\n",
    "The third estimator $\\hat{B}_{\\textbf{2} + \\tilde{\\textbf{S}} \\tilde{\\textbf{K}}  }$ is the overidentified bivariate recursive SVAR estimator based on Equation (15).\n",
    "\n",
    "Overidentified GMM estimators with many moment conditions can suffer from a small sample bias. Therefore, the overidentified estimators are implemented using a continuous updating estimator (CUE) instead of a GMM estimator. The CUE continuously updates the weighting, that is, the weighting matrix using the assumption of independent shocks to estimate the efficient weighting matrix, see Keweloh (2023). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = 'CUE'\n",
    "estimator_name = 'CUE-MI'\n",
    "prepOptions = dict()\n",
    "prepOptions['printOutput'] = True\n",
    "prepOptions['bstartopt'] = 'Rec'\n",
    "prepOptions['n_rec'] = n\n",
    "prepOptions['addThirdMoments'] = True\n",
    "prepOptions['addFourthMoments'] = True\n",
    "prepOptions['moments_MeanIndep'] = False\n",
    "prepOptions['moments_blocks'] = False\n",
    "prepOptions['onlybivariate'] = True\n",
    "prepOptions['Wpara'] = 'Independent'\n",
    "prepOptions['Avarparametric'] = 'Independent'\n",
    "prepOptions['S_func'] = True\n",
    "prepOptions['WupdateInOutput'] = False\n",
    "\n",
    "\n",
    "\n",
    "GMM_out = SVAR.SVARest(u, estimator=estimator, prepOptions=prepOptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiUoCROLU4Qv"
   },
   "source": [
    "## References\n",
    "\n",
    "Keweloh, Sascha Alexander, and Wang, Shu. \"Higher Moments and  Efficiency Gains in Recursive Structural Vector Autoregressions.\" Oxford Bulletin of Economics and Statistics (2025) \n",
    "\n",
    "Keweloh, Sascha Alexander. \"Structural vector autoregressions and higher moments: Challenges\n",
    "and solutions in small samples.\" arXiv preprint arXiv:2310.08173 (2023)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
